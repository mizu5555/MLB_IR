"""
Week 2: Query åˆ†é¡å™¨
ä½¿ç”¨ Llama åˆ¤æ–·æŸ¥è©¢é¡å‹

æŸ¥è©¢é¡å‹ï¼š
1. Factualï¼šè©¢å•ç‰¹å®šçƒå“¡çš„æŸå€‹æ•¸æ“š
   - ä¾‹ï¼šã€ŒAaron Judge 2024 wRC+ æ˜¯å¤šå°‘ï¼Ÿã€
   - ç­–ç•¥ï¼šVector Search â†’ æ‰¾åˆ°çƒå“¡ â†’ è¿”å›æ•¸æ“š

2. Rankingï¼šè¦æ±‚æ’åºæˆ–æ¯”è¼ƒ
   - ä¾‹ï¼šã€Œ2024 å¹´ wRC+ æœ€é«˜çš„æ‰“è€…æ˜¯èª°ï¼Ÿã€
   - ç­–ç•¥ï¼šè³‡æ–™åº«æ’åº â†’ è¿”å› Top N

3. Analysisï¼šæ·±åº¦åˆ†ææˆ–è§£é‡‹
   - ä¾‹ï¼šã€Œç‚ºä»€éº¼ Aaron Judge é€™éº¼å¼·ï¼Ÿã€
   - ç­–ç•¥ï¼šå¤šç¶­æ•¸æ“š â†’ LLM åˆ†æ
"""

import json
import os
from typing import Dict, Literal

print("=" * 80)
print("Query åˆ†é¡å™¨æ¸¬è©¦")
print("=" * 80)

# ============================================
# é…ç½®
# ============================================

# ä½ å¯ä»¥é¸æ“‡ä½¿ç”¨çš„ LLM
LLM_TYPE = "ollama"  # å¯é¸ï¼šollama, openai, anthropic

# Ollama é…ç½®ï¼ˆæœ¬åœ°é‹è¡Œï¼‰
OLLAMA_MODEL = "llama3.2"  # æˆ– llama3, mistral, ç­‰
OLLAMA_BASE_URL = "http://localhost:11434"

print(f"\né…ç½®ï¼š")
print(f"  LLM é¡å‹ï¼š{LLM_TYPE}")
if LLM_TYPE == "ollama":
    print(f"  Ollama æ¨¡å‹ï¼š{OLLAMA_MODEL}")
    print(f"  Ollama URLï¼š{OLLAMA_BASE_URL}")

# ============================================
# Query åˆ†é¡ Prompt
# ============================================

CLASSIFICATION_PROMPT = """You are a query classifier for a baseball statistics system.

Classify the following query into ONE of these types:

1. **factual**: Query asks for specific data about a specific player
   Examples:
   - "Aaron Judge 2024 wRC+"
   - "What is Shohei Ohtani's ERA?"
   - "How many home runs did Juan Soto hit?"

2. **ranking**: Query asks for top/best/worst players or comparisons
   Examples:
   - "Who has the highest wRC+ in 2024?"
   - "Top 5 pitchers by ERA"
   - "Best hitters this season"

3. **analysis**: Query asks for explanation, reasoning, or deep analysis
   Examples:
   - "Why is Aaron Judge so good?"
   - "Explain Shohei Ohtani's performance"
   - "What makes this pitcher effective?"

Query: "{query}"

CRITICAL: Respond with ONLY ONE WORD: factual, ranking, or analysis
Do not include any explanation or additional text.
"""

# ============================================
# LLM æ¥å£
# ============================================

def call_llm(prompt: str) -> str:
    """
    èª¿ç”¨ LLM ç”Ÿæˆå›ç­”
    æ”¯æ´ Ollama (æœ¬åœ°) å’Œå…¶ä»– API
    """
    
    if LLM_TYPE == "ollama":
        try:
            import requests
            
            response = requests.post(
                f"{OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": OLLAMA_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.0,  # ç¢ºä¿çµæœä¸€è‡´
                        "num_predict": 10,   # åªéœ€è¦ä¸€å€‹è©
                    }
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['response'].strip()
            else:
                raise Exception(f"Ollama API éŒ¯èª¤ï¼š{response.status_code}")
                
        except Exception as e:
            print(f"  âš ï¸  Ollama èª¿ç”¨å¤±æ•—ï¼š{e}")
            print(f"  è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œï¼šollama serve")
            print(f"  ä¸¦å·²ä¸‹è¼‰æ¨¡å‹ï¼šollama pull {OLLAMA_MODEL}")
            raise
    
    elif LLM_TYPE == "openai":
        # OpenAI API å¯¦ä½œï¼ˆéœ€è¦ API keyï¼‰
        try:
            import openai
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=10
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"  âš ï¸  OpenAI API éŒ¯èª¤ï¼š{e}")
            raise
    
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„ LLM é¡å‹ï¼š{LLM_TYPE}")

# ============================================
# Query åˆ†é¡å™¨
# ============================================

def classify_query(query: str) -> Dict:
    """
    åˆ†é¡æŸ¥è©¢é¡å‹
    
    Returns:
        {
            'query': str,
            'type': 'factual' | 'ranking' | 'analysis',
            'confidence': float,
            'raw_response': str
        }
    """
    
    print(f"\næŸ¥è©¢ï¼š'{query}'")
    print(f"  æ­£åœ¨åˆ†é¡...")
    
    # æº–å‚™ prompt
    prompt = CLASSIFICATION_PROMPT.format(query=query)
    
    # èª¿ç”¨ LLM
    try:
        raw_response = call_llm(prompt)
        print(f"  LLM å›æ‡‰ï¼š'{raw_response}'")
        
        # è§£æå›æ‡‰ï¼ˆæå–ç¬¬ä¸€å€‹æœ‰æ•ˆçš„é¡å‹è©ï¼‰
        response_lower = raw_response.lower().strip()
        
        # å˜—è©¦å¾å›æ‡‰ä¸­æ‰¾åˆ°é¡å‹
        query_type = None
        if 'factual' in response_lower:
            query_type = 'factual'
        elif 'ranking' in response_lower:
            query_type = 'ranking'
        elif 'analysis' in response_lower:
            query_type = 'analysis'
        else:
            # Fallbackï¼šå¦‚æœç„¡æ³•åˆ¤æ–·ï¼Œé»˜èªç‚º factual
            print(f"  âš ï¸  ç„¡æ³•è§£æå›æ‡‰ï¼Œä½¿ç”¨é è¨­é¡å‹ 'factual'")
            query_type = 'factual'
        
        result = {
            'query': query,
            'type': query_type,
            'raw_response': raw_response,
            'confidence': 1.0 if query_type else 0.5
        }
        
        print(f"  âœ… åˆ†é¡çµæœï¼š{query_type}")
        return result
        
    except Exception as e:
        print(f"  âŒ åˆ†é¡å¤±æ•—ï¼š{e}")
        # Fallback
        return {
            'query': query,
            'type': 'factual',
            'raw_response': '',
            'confidence': 0.0,
            'error': str(e)
        }

# ============================================
# æ¸¬è©¦æ¡ˆä¾‹
# ============================================

test_queries = [
    # Factual
    "Aaron Judge 2024 wRC+",
    "What is Shohei Ohtani's ERA in 2024?",
    "How many home runs did Juan Soto hit?",
    
    # Ranking
    "Who has the highest wRC+ in 2024?",
    "Top 5 pitchers by ERA",
    "Best hitters this season",
    "èª°æ˜¯ 2024 å¹´æœ€å¼·çš„æ‰“è€…ï¼Ÿ",
    
    # Analysis
    "Why is Aaron Judge so good?",
    "Explain Shohei Ohtani's performance",
    "What makes Clayton Kershaw effective?",
    "ç‚ºä»€éº¼ Aaron Judge å£“åˆ¶åŠ›é€™éº¼å¼·ï¼Ÿ",
]

# ============================================
# åŸ·è¡Œæ¸¬è©¦
# ============================================

print("\n" + "=" * 80)
print("é–‹å§‹æ¸¬è©¦")
print("=" * 80)

results = []

for query in test_queries:
    result = classify_query(query)
    results.append(result)
    print()

# ============================================
# çµ±è¨ˆçµæœ
# ============================================

print("\n" + "=" * 80)
print("åˆ†é¡çµ±è¨ˆ")
print("=" * 80)

type_counts = {}
for result in results:
    qtype = result['type']
    type_counts[qtype] = type_counts.get(qtype, 0) + 1

print("\nåˆ†é¡åˆ†ä½ˆï¼š")
for qtype, count in type_counts.items():
    print(f"  {qtype}: {count} ç­† ({count/len(results)*100:.1f}%)")

# ============================================
# å„²å­˜çµæœ
# ============================================

output_dir = "./mlb_data"
os.makedirs(output_dir, exist_ok=True)

output_file = os.path.join(output_dir, "query_classification_results.json")
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f"\nğŸ’¾ çµæœå·²å„²å­˜ï¼š{output_file}")

# ============================================
# çµè«–
# ============================================

print("\n" + "=" * 80)
print("æ¸¬è©¦å®Œæˆ")
print("=" * 80)

successful = sum(1 for r in results if r.get('confidence', 0) > 0)
print(f"âœ… æˆåŠŸåˆ†é¡ï¼š{successful}/{len(results)} ({successful/len(results)*100:.1f}%)")

print("\nğŸ“Š åˆ†é¡ç¯„ä¾‹ï¼š")
for result in results[:5]:  # é¡¯ç¤ºå‰ 5 å€‹
    print(f"  '{result['query'][:40]}...' â†’ {result['type']}")

print("\nğŸ¯ ä¸‹ä¸€æ­¥ï¼š")
print("  1. é©—è­‰åˆ†é¡æº–ç¢ºæ€§")
print("  2. åŸ·è¡Œ week2_smart_router.py å»ºç«‹æ™ºèƒ½è·¯ç”±")
print("  3. æ•´åˆ Vector Search å’Œè³‡æ–™åº«æ’åº")
print("=" * 80)
