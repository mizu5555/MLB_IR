"""
Week 3: è‡ªå‹•è©•ä¼°ç³»çµ±
è©•ä¼°æŒ‡æ¨™ï¼šQuery åˆ†é¡æº–ç¢ºç‡ã€Recall@kã€æ•¸æ“šæº–ç¢ºç‡ã€Ranking è³ªé‡
"""

import json
import os
import sys
from typing import Dict, List

# å°å…¥ MLB Assistant
sys.path.append('.')
from week2_mlb_assistant import mlb_assistant, classify_query, vector_search

print("=" * 80)
print("Week 3: è‡ªå‹•è©•ä¼°ç³»çµ±")
print("=" * 80)

# ============================================
# è¼‰å…¥æ¸¬è©¦é›†
# ============================================

def load_test_queries(file_path: str = "./mlb_data/week3_test_queries.json") -> Dict:
    """è¼‰å…¥æ¸¬è©¦æŸ¥è©¢"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# ============================================
# è©•ä¼° 1: Query åˆ†é¡æº–ç¢ºç‡
# ============================================

def evaluate_classification(test_queries: Dict) -> Dict:
    """è©•ä¼° Query åˆ†é¡æº–ç¢ºç‡"""
    
    print("\n" + "=" * 80)
    print("[è©•ä¼° 1] Query åˆ†é¡æº–ç¢ºç‡")
    print("=" * 80)
    
    results = {
        'total': 0,
        'correct': 0,
        'by_type': {
            'factual': {'total': 0, 'correct': 0},
            'ranking': {'total': 0, 'correct': 0},
            'analysis': {'total': 0, 'correct': 0}
        },
        'errors': []
    }
    
    for query_type in ['factual', 'ranking', 'analysis']:
        print(f"\næ¸¬è©¦ {query_type.upper()} æŸ¥è©¢...")
        
        for test_case in test_queries[query_type]:
            query = test_case['query']
            expected_type = test_case['expected_type']
            test_id = test_case['id']
            
            # åˆ†é¡
            predicted_type = classify_query(query)
            
            # çµ±è¨ˆ
            results['total'] += 1
            results['by_type'][expected_type]['total'] += 1
            
            if predicted_type == expected_type:
                results['correct'] += 1
                results['by_type'][expected_type]['correct'] += 1
                print(f"  âœ… {test_id}: '{query[:40]}...' â†’ {predicted_type}")
            else:
                results['by_type'][expected_type]['total'] += 1
                results['errors'].append({
                    'test_id': test_id,
                    'query': query,
                    'expected': expected_type,
                    'predicted': predicted_type
                })
                print(f"  âŒ {test_id}: '{query[:40]}...' â†’ Expected: {expected_type}, Got: {predicted_type}")
    
    # è¨ˆç®—æº–ç¢ºç‡
    results['accuracy'] = results['correct'] / results['total'] if results['total'] > 0 else 0
    
    for query_type in ['factual', 'ranking', 'analysis']:
        total = results['by_type'][query_type]['total']
        correct = results['by_type'][query_type]['correct']
        results['by_type'][query_type]['accuracy'] = correct / total if total > 0 else 0
    
    # é¡¯ç¤ºçµæœ
    print("\n" + "-" * 80)
    print("åˆ†é¡æº–ç¢ºç‡ç¸½çµï¼š")
    print(f"  ç¸½æº–ç¢ºç‡ï¼š{results['accuracy']:.1%} ({results['correct']}/{results['total']})")
    print(f"  Factualï¼š{results['by_type']['factual']['accuracy']:.1%} ({results['by_type']['factual']['correct']}/{results['by_type']['factual']['total']})")
    print(f"  Rankingï¼š{results['by_type']['ranking']['accuracy']:.1%} ({results['by_type']['ranking']['correct']}/{results['by_type']['ranking']['total']})")
    print(f"  Analysisï¼š{results['by_type']['analysis']['accuracy']:.1%} ({results['by_type']['analysis']['correct']}/{results['by_type']['analysis']['total']})")
    
    if results['errors']:
        print(f"\n  âš ï¸  éŒ¯èª¤åˆ†é¡ï¼š{len(results['errors'])} ç­†")
        for error in results['errors'][:5]:
            print(f"    {error['test_id']}: '{error['query'][:40]}...'")
            print(f"      Expected: {error['expected']}, Got: {error['predicted']}")
    
    return results

# ============================================
# è©•ä¼° 2: Factual æŸ¥è©¢æº–ç¢ºæ€§
# ============================================

def evaluate_factual_accuracy(test_queries: Dict) -> Dict:
    """è©•ä¼° Factual æŸ¥è©¢çš„çƒå“¡è­˜åˆ¥å’Œæ•¸æ“šæº–ç¢ºæ€§"""
    
    print("\n" + "=" * 80)
    print("[è©•ä¼° 2] Factual æŸ¥è©¢æº–ç¢ºæ€§")
    print("=" * 80)
    
    results = {
        'total': 0,
        'correct_player': 0,
        'correct_value': 0,
        'player_errors': [],
        'value_errors': []
    }
    
    value_test_count = 0
    
    for test_case in test_queries['factual']:
        query = test_case['query']
        expected_player = test_case.get('expected_player')
        expected_stat = test_case.get('expected_stat')
        expected_value = test_case.get('expected_value')
        test_id = test_case['id']
        
        # åŸ·è¡ŒæŸ¥è©¢
        print(f"\næ¸¬è©¦ {test_id}: '{query}'")
        try:
            result = mlb_assistant(query)
            
            results['total'] += 1
            
            # æª¢æŸ¥çƒå“¡
            if result['data'].get('top_result'):
                player_name = result['data']['top_result']['player_name']
                
                if expected_player and expected_player.lower() in player_name.lower():
                    results['correct_player'] += 1
                    print(f"  âœ… çƒå“¡æ­£ç¢ºï¼š{player_name}")
                else:
                    results['player_errors'].append({
                        'test_id': test_id,
                        'query': query,
                        'expected': expected_player,
                        'actual': player_name
                    })
                    print(f"  âŒ çƒå“¡éŒ¯èª¤ï¼šExpected {expected_player}, Got {player_name}")
                
                # æª¢æŸ¥æ•¸å€¼ï¼ˆå¦‚æœæœ‰æœŸæœ›å€¼ï¼‰
                if expected_stat and expected_value:
                    value_test_count += 1
                    stat_key = f"stat_{expected_stat}"
                    actual_value = result['data']['top_result'].get(stat_key)
                    
                    if actual_value and abs(actual_value - expected_value) < 1:
                        results['correct_value'] += 1
                        print(f"  âœ… æ•¸å€¼æ­£ç¢ºï¼š{expected_stat} = {actual_value:.3f}")
                    else:
                        results['value_errors'].append({
                            'test_id': test_id,
                            'query': query,
                            'stat': expected_stat,
                            'expected': expected_value,
                            'actual': actual_value
                        })
                        print(f"  âŒ æ•¸å€¼éŒ¯èª¤ï¼šExpected {expected_value}, Got {actual_value}")
            
        except Exception as e:
            print(f"  âŒ éŒ¯èª¤ï¼š{e}")
            results['player_errors'].append({
                'test_id': test_id,
                'query': query,
                'error': str(e)
            })
    
    # è¨ˆç®—æº–ç¢ºç‡
    results['player_accuracy'] = results['correct_player'] / results['total'] if results['total'] > 0 else 0
    if value_test_count > 0:
        results['value_accuracy'] = results['correct_value'] / value_test_count
        results['value_test_count'] = value_test_count
    
    # é¡¯ç¤ºçµæœ
    print("\n" + "-" * 80)
    print("Factual æŸ¥è©¢æº–ç¢ºæ€§ç¸½çµï¼š")
    print(f"  çƒå“¡è­˜åˆ¥æº–ç¢ºç‡ï¼š{results['player_accuracy']:.1%} ({results['correct_player']}/{results['total']})")
    if value_test_count > 0:
        print(f"  æ•¸å€¼æº–ç¢ºç‡ï¼š{results['value_accuracy']:.1%} ({results['correct_value']}/{value_test_count})")
    
    return results

# ============================================
# è©•ä¼° 3: Ranking æŸ¥è©¢è³ªé‡
# ============================================

def evaluate_ranking_quality(test_queries: Dict) -> Dict:
    """è©•ä¼° Ranking æŸ¥è©¢çš„æ’åºè³ªé‡"""
    
    print("\n" + "=" * 80)
    print("[è©•ä¼° 3] Ranking æŸ¥è©¢è³ªé‡")
    print("=" * 80)
    
    results = {
        'total': 0,
        'correct_top_1': 0,
        'correct_stat': 0,
        'errors': []
    }
    
    top_1_test_count = 0
    
    for test_case in test_queries['ranking']:
        query = test_case['query']
        expected_top_1 = test_case.get('expected_top_1')
        expected_stat = test_case.get('expected_stat')
        test_id = test_case['id']
        
        # åŸ·è¡ŒæŸ¥è©¢
        print(f"\næ¸¬è©¦ {test_id}: '{query}'")
        try:
            result = mlb_assistant(query)
            
            results['total'] += 1
            
            # æª¢æŸ¥çµ±è¨ˆé¡å‹
            if result['data'].get('stat_name'):
                actual_stat = result['data']['stat_name']
                if expected_stat and expected_stat.lower() in actual_stat.lower():
                    results['correct_stat'] += 1
                    print(f"  âœ… çµ±è¨ˆé¡å‹æ­£ç¢ºï¼š{actual_stat}")
                else:
                    print(f"  âš ï¸  çµ±è¨ˆé¡å‹ï¼šExpected {expected_stat}, Got {actual_stat}")
            
            # æª¢æŸ¥ Top 1
            if result['data'].get('results') and expected_top_1:
                top_1_test_count += 1
                top_player = result['data']['results'][0]['name']
                
                if expected_top_1.lower() in top_player.lower():
                    results['correct_top_1'] += 1
                    print(f"  âœ… Top 1 æ­£ç¢ºï¼š{top_player}")
                else:
                    results['errors'].append({
                        'test_id': test_id,
                        'query': query,
                        'expected_top_1': expected_top_1,
                        'actual_top_1': top_player
                    })
                    print(f"  âŒ Top 1 éŒ¯èª¤ï¼šExpected {expected_top_1}, Got {top_player}")
        
        except Exception as e:
            print(f"  âŒ éŒ¯èª¤ï¼š{e}")
            results['errors'].append({
                'test_id': test_id,
                'query': query,
                'error': str(e)
            })
    
    # è¨ˆç®—æº–ç¢ºç‡
    results['stat_accuracy'] = results['correct_stat'] / results['total'] if results['total'] > 0 else 0
    if top_1_test_count > 0:
        results['top_1_accuracy'] = results['correct_top_1'] / top_1_test_count
        results['top_1_test_count'] = top_1_test_count
    
    # é¡¯ç¤ºçµæœ
    print("\n" + "-" * 80)
    print("Ranking æŸ¥è©¢è³ªé‡ç¸½çµï¼š")
    print(f"  çµ±è¨ˆé¡å‹æº–ç¢ºç‡ï¼š{results['stat_accuracy']:.1%} ({results['correct_stat']}/{results['total']})")
    if top_1_test_count > 0:
        print(f"  Top 1 æº–ç¢ºç‡ï¼š{results['top_1_accuracy']:.1%} ({results['correct_top_1']}/{top_1_test_count})")
    
    return results

# ============================================
# è©•ä¼° 4: Analysis æŸ¥è©¢
# ============================================

def evaluate_analysis_queries(test_queries: Dict) -> Dict:
    """è©•ä¼° Analysis æŸ¥è©¢"""
    
    print("\n" + "=" * 80)
    print("[è©•ä¼° 4] Analysis æŸ¥è©¢")
    print("=" * 80)
    
    results = {
        'total': 0,
        'correct_player': 0,
        'has_multi_season': 0,
        'errors': []
    }
    
    for test_case in test_queries['analysis']:
        query = test_case['query']
        expected_player = test_case.get('expected_player')
        test_id = test_case['id']
        
        # åŸ·è¡ŒæŸ¥è©¢
        print(f"\næ¸¬è©¦ {test_id}: '{query}'")
        try:
            result = mlb_assistant(query)
            
            results['total'] += 1
            
            # æª¢æŸ¥çƒå“¡
            if result['data'].get('player_name'):
                player_name = result['data']['player_name']
                
                if expected_player and expected_player.lower() in player_name.lower():
                    results['correct_player'] += 1
                    print(f"  âœ… çƒå“¡æ­£ç¢ºï¼š{player_name}")
                else:
                    results['errors'].append({
                        'test_id': test_id,
                        'query': query,
                        'expected': expected_player,
                        'actual': player_name
                    })
                    print(f"  âŒ çƒå“¡éŒ¯èª¤ï¼šExpected {expected_player}, Got {player_name}")
                
                # æª¢æŸ¥æ˜¯å¦æ”¶é›†å¤šè³½å­£æ•¸æ“š
                stats_over_time = result['data'].get('stats_over_time', [])
                if len(stats_over_time) > 1:
                    results['has_multi_season'] += 1
                    print(f"  âœ… å¤šè³½å­£æ•¸æ“šï¼š{len(stats_over_time)} å€‹è³½å­£")
                else:
                    print(f"  âš ï¸  åªæœ‰ {len(stats_over_time)} å€‹è³½å­£æ•¸æ“š")
        
        except Exception as e:
            print(f"  âŒ éŒ¯èª¤ï¼š{e}")
            results['errors'].append({
                'test_id': test_id,
                'query': query,
                'error': str(e)
            })
    
    # è¨ˆç®—æº–ç¢ºç‡
    results['player_accuracy'] = results['correct_player'] / results['total'] if results['total'] > 0 else 0
    results['multi_season_rate'] = results['has_multi_season'] / results['total'] if results['total'] > 0 else 0
    
    # é¡¯ç¤ºçµæœ
    print("\n" + "-" * 80)
    print("Analysis æŸ¥è©¢ç¸½çµï¼š")
    print(f"  çƒå“¡è­˜åˆ¥æº–ç¢ºç‡ï¼š{results['player_accuracy']:.1%} ({results['correct_player']}/{results['total']})")
    print(f"  å¤šè³½å­£æ•¸æ“šæ”¶é›†ç‡ï¼š{results['multi_season_rate']:.1%} ({results['has_multi_season']}/{results['total']})")
    
    return results

# ============================================
# ä¸»åŸ·è¡Œå‡½æ•¸
# ============================================

def run_evaluation():
    """åŸ·è¡Œå®Œæ•´è©•ä¼°"""
    
    # è¼‰å…¥æ¸¬è©¦é›†
    print("\n[è¼‰å…¥æ¸¬è©¦é›†]")
    test_queries = load_test_queries()
    print(f"  âœ… Factual: {len(test_queries['factual'])} ç­†")
    print(f"  âœ… Ranking: {len(test_queries['ranking'])} ç­†")
    print(f"  âœ… Analysis: {len(test_queries['analysis'])} ç­†")
    print(f"  âœ… ç¸½è¨ˆ: {len(test_queries['factual']) + len(test_queries['ranking']) + len(test_queries['analysis'])} ç­†")
    
    # è©•ä¼° 1ï¼šåˆ†é¡æº–ç¢ºç‡
    classification_results = evaluate_classification(test_queries)
    
    # è©•ä¼° 2ï¼šFactual æº–ç¢ºæ€§
    factual_results = evaluate_factual_accuracy(test_queries)
    
    # è©•ä¼° 3ï¼šRanking è³ªé‡
    ranking_results = evaluate_ranking_quality(test_queries)
    
    # è©•ä¼° 4ï¼šAnalysis æŸ¥è©¢
    analysis_results = evaluate_analysis_queries(test_queries)
    
    # å„²å­˜çµæœ
    output = {
        'metadata': test_queries['metadata'],
        'classification': classification_results,
        'factual': factual_results,
        'ranking': ranking_results,
        'analysis': analysis_results
    }
    
    output_file = "./mlb_data/week3_evaluation_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 80)
    print("è©•ä¼°å®Œæˆ")
    print("=" * 80)
    print(f"\nğŸ’¾ è©³ç´°çµæœå·²å„²å­˜ï¼š{output_file}")
    
    # ç¸½çµå ±å‘Š
    print("\n" + "=" * 80)
    print("ğŸ“Š ç¸½çµå ±å‘Š")
    print("=" * 80)
    print(f"\nâœ… Query åˆ†é¡æº–ç¢ºç‡ï¼š{classification_results['accuracy']:.1%}")
    print(f"   - Factual: {classification_results['by_type']['factual']['accuracy']:.1%}")
    print(f"   - Ranking: {classification_results['by_type']['ranking']['accuracy']:.1%}")
    print(f"   - Analysis: {classification_results['by_type']['analysis']['accuracy']:.1%}")
    
    print(f"\nâœ… Factual æŸ¥è©¢æº–ç¢ºæ€§ï¼š")
    print(f"   - çƒå“¡è­˜åˆ¥ï¼š{factual_results['player_accuracy']:.1%}")
    if 'value_accuracy' in factual_results:
        print(f"   - æ•¸å€¼æº–ç¢ºç‡ï¼š{factual_results['value_accuracy']:.1%}")
    
    print(f"\nâœ… Ranking æŸ¥è©¢è³ªé‡ï¼š")
    print(f"   - çµ±è¨ˆé¡å‹ï¼š{ranking_results['stat_accuracy']:.1%}")
    if 'top_1_accuracy' in ranking_results:
        print(f"   - Top 1 æº–ç¢ºç‡ï¼š{ranking_results['top_1_accuracy']:.1%}")
    
    print(f"\nâœ… Analysis æŸ¥è©¢ï¼š")
    print(f"   - çƒå“¡è­˜åˆ¥ï¼š{analysis_results['player_accuracy']:.1%}")
    print(f"   - å¤šè³½å­£æ•¸æ“šï¼š{analysis_results['multi_season_rate']:.1%}")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    run_evaluation()
